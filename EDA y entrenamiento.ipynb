{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el set de testeo provisto\n",
    "inmuebles = pd.read_parquet(\"train.parquet\")\n",
    "testeo_henry = pd.read_parquet(\"test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos las primeras lineas del dataset\n",
    "inmuebles.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos existencia de valores nulos\n",
    "inmuebles.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a crear la nueva columna con las dos categorias de precios (1 = low, 0 = medium & high)\n",
    "conditions = [\n",
    "    (inmuebles['price'] >= 0) & (inmuebles['price'] <= 999),\n",
    "    (inmuebles['price'] >= 1000)]\n",
    "choices = ['1', '0']\n",
    "inmuebles['category_price'] = np.select(conditions, choices).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos valores de la nueva columna y existencia de nulos\n",
    "inmuebles.category_price.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la distribución de la nueva columna\n",
    "sns.countplot(x='category_price', data=inmuebles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las clases se encuentran balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos existenvia de filas duplicadas\n",
    "len(inmuebles)-len(inmuebles.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorando el dataset, encontramos Descripciones repetidas, generalmente con mismo precio de alquiler y mismo URL de la imagen de la propiedad, por lo que decidimos eliminar estos registros repetidos dejando solamente uno, utilizando para ello la columna de la URL de la imagen ya que es la que mayor confianza nos otorga en cuanto a que se trata de la misma propiedad en alquiler."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos que el dato de cuantas veces se publicó la misma propiedad puede ser un indicativo del valor de su alquiler. Por lo tanto, vamos a incorporar una columna con la cantidad de veces que se publicó el aviso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos la cantidad de valores repetidos en la columna \"image_url\"\n",
    "len(inmuebles['image_url'])-len(inmuebles['image_url'].drop_duplicates())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que un número importante, practicamente la mitad del dataset contiene republicaciones de la misma propieadad en alquiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos algun ejemplo para visualizar\n",
    "df = inmuebles.loc[inmuebles['image_url'].duplicated(keep=False),'image_url']\n",
    "df\n",
    "df = df.groupby(df).apply(lambda x: tuple(x.index)).tolist()\n",
    "df[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.loc[[66499,70514, 173295,215379,309342,331892],['price','image_url','description']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conciden los datos, con una pequeña variación en el costo del alquiler que puede deberse al paso del tiempo y la inflaciòn de Estados Unidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporamos una columna \"publicaciones\" que contiene la cantidad de veces que aparece el mismo anuncio en el dataset\n",
    "inmuebles['publicaciones'] = inmuebles.groupby(['image_url'])['image_url'].transform('count')\n",
    "testeo_henry['publicaciones'] = testeo_henry.groupby(['image_url'])['image_url'].transform('count')\n",
    "inmuebles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora si eliminamos los anuncios duplicados\n",
    "inmuebles.drop_duplicates(subset='image_url', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, hemos reducido el dataset en un 51,4% del total de registros originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar la distribución del target\n",
    "sns.countplot(x='category_price', data=inmuebles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a analizar ahora cada columna en particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos la existencia de outliers en varias columnas, por ejemplo, un valor máximo de 1.100 camas o 75 baños. Analizaremos a continuación cada una de las columnas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizemos \"sqfeet\" en busqueda de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.sort_values(\"sqfeet\",ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay valores muy altos y valores en cero. De acuerdo a este artículo (https://www.ahs.com/home-matters/real-estate/the-2022-american-home-size-index/) el promedio de square feet de las viviendas en Estados Unidos se acerca de 2.000.\n",
    "Por lo tanto, podemos considerar los valores superiores a 50.000 como errores (especialmente tratandose de alquileres).\n",
    "Tambien consideraremos errores los valores de cero y muy bajos, ya que de acuerdo a este otro artículo (https://www.nyrentownsell.com/blog/square-footage-guide-to-living-real-life-home-example/) , 200 square feets es el mínimo para que la vivienda sea habitable\n",
    "Calcularemos los outliers a continuacion utilizando el método del Rango Intercuartílico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_treatment(datacolumn):\n",
    "    \"\"\"\n",
    "    Definimos una función para detectar outliers\n",
    "    \"\"\"\n",
    "    sorted(datacolumn)\n",
    "    Q1,Q3 = np.percentile(datacolumn , [25,75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower_range = Q1 - (1.5 * IQR)\n",
    "    upper_range = Q3 + (1.5 * IQR)\n",
    "    return lower_range,upper_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los valores límites inferior y superior\n",
    "lowerbound,upperbound = outlier_treatment(inmuebles.sqfeet)\n",
    "print (\"Lower:\",lowerbound,\" \",\"Upper\",upperbound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos algunos ejemplos de outliers\n",
    "inmuebles[(inmuebles.sqfeet < lowerbound) | (inmuebles.sqfeet > upperbound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos\n",
    "sns.boxplot(x=\"sqfeet\", data=inmuebles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos sin outliers\n",
    "sns.boxplot(x = 'sqfeet', data = inmuebles, showfliers = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos en las gráficas, la cantidad de valores errones es importante. Por un lado, el valor mínimo de 75 squarefeet es muy bajo en relacion a los 200 squarefeet mencionados, con muchos casos dentro del primer cuartil con esos valores, y por otro lado, el valor mínimo de 1.875 es inferior al promedio del tamaño de viviendas en Estados Unidos.\n",
    "Tomaremos entonces como valor mínimo válido 200 squarefeet y como valor máximo, 10.000 squarefeet, reemplazando los valores que exceden los límites, por dichos límites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles['sqfeet'].mask(inmuebles['sqfeet'] < 200, 200, inplace=True)\n",
    "testeo_henry['sqfeet'].mask(testeo_henry['sqfeet'] < 200, 200, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles['sqfeet'].mask(inmuebles['sqfeet'] > 10000, 10000, inplace=True)\n",
    "testeo_henry['sqfeet'].mask(testeo_henry['sqfeet'] > 10000, 10000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a graficar\n",
    "sns.boxplot(x=\"sqfeet\", data=inmuebles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien a simple vista la gráfica indicaria la presencia abundante de outliers aún, consideramos que se relaciona satisfactoriamente a los datos recolectados. Una gran cantidad de propiedades en alquiler por debajo del tamaño promedio de las mismas en Estados Unidos, y una menor cantidad de propiedades de tamaños muy superiores a la media."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna \"publicaciones\" tiene valores (si bien reales), muy superiores a la media. Tomaremos como máximo 30 publicaciones. Ademas consideramos que el set de testeo, al contar con menos casos, no tendrá tantas repeticiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles['publicaciones'].mask(inmuebles['publicaciones'] > 30, 30, inplace=True)\n",
    "testeo_henry['publicaciones'].mask(testeo_henry['publicaciones'] > 30, 30, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos\n",
    "sns.boxplot( y=inmuebles[\"publicaciones\"] )\n",
    "plt.ylim(1, 30)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora las columnas de camas y baños, que parecen tener outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos camas\n",
    "sns.boxplot(x=\"beds\", data=inmuebles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora sin outliers\n",
    "sns.boxplot(x = 'beds', data = inmuebles, showfliers = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazaremos los valores en 0 por 1 y los valores mayores a 8 por 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles['beds'].mask(inmuebles['beds'] == 0, 1, inplace=True)\n",
    "inmuebles['beds'].mask(inmuebles['beds'] > 8, 8, inplace=True)\n",
    "testeo_henry['beds'].mask(testeo_henry['beds'] == 0, 1, inplace=True)\n",
    "testeo_henry['beds'].mask(testeo_henry['beds'] > 8, 8, inplace=True)\n",
    "sns.boxplot(x=\"beds\", data=inmuebles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos baños\n",
    "sns.boxplot(x=\"baths\", data=inmuebles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazaremos los valores en 0 por 1 y los valores mayores a 8 por 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles['baths'].mask(inmuebles['baths'] == 0, 1, inplace=True)\n",
    "inmuebles['baths'].mask(inmuebles['baths'] > 8, 8, inplace=True)\n",
    "testeo_henry['baths'].mask(testeo_henry['baths'] == 0, 1, inplace=True)\n",
    "testeo_henry['baths'].mask(testeo_henry['baths'] > 8, 8, inplace=True)\n",
    "sns.boxplot(x=\"baths\", data=inmuebles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos ahora la columna de Longitud. Vemos que hay valores en positivo que son erroneos, muchos casos son de Arkansas y vemos que si lo pasamos a negativo, coinciden con la ubicacion de ese Estado. Les cambiamos entonces el signo a los positivos y pasamos a -67.482 los valores mayores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles[\"long\"] = inmuebles[\"long\"].abs()*(-1)\n",
    "testeo_henry[\"long\"] = testeo_henry[\"long\"].abs()*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles['long'].mask(inmuebles['long'] > (-67.482), (-67.482), inplace=True)\n",
    "testeo_henry['long'].mask(testeo_henry['long'] > (-67.482), (-67.482), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos existencia de valores nulos\n",
    "inmuebles[\"long\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos nulos por el promedio\n",
    "inmuebles['long'].fillna(int(inmuebles['long'].mean()), inplace=True)\n",
    "testeo_henry['long'].fillna(int(testeo_henry['long'].mean()), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos la columna de Servicio de Lavanderia. Vemos las opciones que contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles[\"laundry_options\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.laundry_options.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la cantidad de valores nulos es importante. Asumiremos que corresponden a que el inmueble no tiene el servicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles[\"laundry_options\"].fillna(\"no laundry on site\", inplace = True)\n",
    "testeo_henry[\"laundry_options\"].fillna(\"no laundry on site\", inplace = True)\n",
    "inmuebles.laundry_options.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos la variable categorica en numérica. Lo hacemos de manera manual para ordenar los valores de acuerdo a la existencia o no del servicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_var = {'laundry_options': {'no laundry on site':0, 'w/d hookups':1, 'laundry on site':2, 'laundry in bldg':3, \"w/d in unit\":4}}\n",
    "inmuebles = inmuebles.replace(numeric_var)\n",
    "testeo_henry = testeo_henry.replace(numeric_var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos la columna de Estacionamiento. Vemos las opciones que contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles[\"parking_options\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.parking_options.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, no podremos eliminar los nulos, y asumimos que corresponde a propiedad sin estacionamiento.\n",
    "Reemplazamos los nulos y luego convertigos a valores numéricos, agrupando algunas categorias similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles[\"parking_options\"].fillna(\"no parking\", inplace = True)\n",
    "testeo_henry[\"parking_options\"].fillna(\"no parking\", inplace = True)\n",
    "inmuebles.parking_options.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_var = {'parking_options': {'no parking':0, 'street parking':0, 'off-street parking':1, 'carport':2, \"detached garage\":2, \"attached garage\":3, \"valet parking\":4}}\n",
    "inmuebles = inmuebles.replace(numeric_var)\n",
    "testeo_henry = testeo_henry.replace(numeric_var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisaremos ahora la correlación de longitud y latitud con el valor del alquiler para evaluar si eliminamos alguna de ellas o ambas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlaciones = inmuebles[[\"lat\",\"long\",\"category_price\"]].copy()\n",
    "correlaciones.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la longitud amerita participar del modelo debido a su correlación con el precio. Entendemos que obedece a que indica cercania con el mar.\n",
    "Eliminaremos latitud, ademas de \"price\" que es un dato que no estará presente en el set de testeo de Henry, y las que creemos que no aportan valor o representan una gran dificultad para incorporar al modelo como \"id\", \"url\", \"region\", \"region_url\", \"image_url\" y \"description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles.drop([\"id\",\"lat\",\"url\", \"region\", \"region_url\", \"image_url\",\"description\",\"price\"],axis = 1, inplace = True)\n",
    "testeo_henry.drop([\"id\",\"lat\",\"url\", \"region\", \"region_url\", \"image_url\",\"description\"],axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos las correlaciones del estado actual del dataframe para eliminar algunas columnas adicionales que en principio no serían de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos)\n",
    "plt.figure(figsize=(6, 10))\n",
    "heatmap = sns.heatmap(inmuebles.corr(method='spearman')[['category_price']].sort_values(by='category_price', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Features Correlating with Category_Price', fontdict={'fontsize':18}, pad=16);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo al gráfico, en un primer modelo usaremos beds, baths, parking options, laundry options, sqfeet, publicaciones, long y si se permite fumar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos la distribución de la columna \"type\"\n",
    "sns.countplot(y='type', data=inmuebles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos la relación entre el precio del alquiler y el tipo de vivienda\n",
    "agr = inmuebles.groupby(['type', 'category_price']).size().reset_index().pivot(columns='category_price', index='type', values=0)\n",
    "agr.plot(kind='bar', stacked=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que en las casas, condominios y townhouses la proporcion de alquileres mayores a $999 es mayor, por lo que en principio dejariamos esta columna. Transformamos a valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_var = {'type': {'land':0, 'in-law':0, 'assisted living':1, 'manufactured':1, \"apartment\":2, \"flat\":3, \"townhouse\":3, \"loft\":4 ,\"duplex\":4, \"house\":3, \"cottage/cabin\":4, \"condo\":5}}\n",
    "inmuebles = inmuebles.replace(numeric_var)\n",
    "testeo_henry = testeo_henry.replace(numeric_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos las nuevas categorias\n",
    "sns.countplot(y='type', data=inmuebles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agr = inmuebles.groupby(['type', 'category_price']).size().reset_index().pivot(columns='category_price', index='type', values=0)\n",
    "agr.plot(kind='bar', stacked=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos en este artículo online (https://www.fool.com/the-ascent/research/average-house-price-state/#:~:text=The%20median%20home%20price%20in,in%20the%20U.S.%20at%20%24354%2C649.), el Estado en el cual se ubican las propiedades tiene gran influencia sobre el precio promedio de las mismas.\n",
    "Por lo tanto, vamos a utilizar la columna \"state\", pero necesitamos transformarla en valores numéricos.\n",
    "Haremos esto mediante el método de Binary Encoding, ya que el One-Hot Encoding nos crearía demasiadas nuevas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles_ce = inmuebles.copy()\n",
    "testeo_henry_ce = testeo_henry.copy()\n",
    "\n",
    "encoder = ce.BinaryEncoder(cols=['state'])\n",
    "inmuebles_binary = encoder.fit_transform(inmuebles_ce)\n",
    "testeo_henry_binary = encoder.fit_transform(testeo_henry_ce)\n",
    "\n",
    "inmuebles_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testeo_henry_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un dataframe para hacer las primeras pruebas\n",
    "inmuebles_v1 = inmuebles_binary\n",
    "testeo_henry_v1 = testeo_henry_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = inmuebles_v1.drop([\"cats_allowed\",\"dogs_allowed\",\"wheelchair_access\", \"electric_vehicle_charge\", \"comes_furnished\", \"category_price\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = inmuebles_v1[\"category_price\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos testeando un modelo de árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train_scores_mean = []\n",
    "tree_train_scores_std = []\n",
    "tree_test_scores_mean = []\n",
    "tree_test_scores_std = []\n",
    "\n",
    "profundidades = np.arange(1,50,1)\n",
    "i = 0\n",
    "i_max = len(profundidades)\n",
    "for profundidad in profundidades:\n",
    "    i = i + 1\n",
    "    clf = DecisionTreeClassifier(max_depth=profundidad)\n",
    "    tree_scores = cross_validate(clf, X, y, cv=5, return_train_score=True, n_jobs = -1)\n",
    "    \n",
    "    tree_train_scores_mean.append(tree_scores['train_score'].mean())\n",
    "    tree_train_scores_std.append(tree_scores['train_score'].std())\n",
    "    \n",
    "    tree_test_scores_mean.append(tree_scores['test_score'].mean())\n",
    "    tree_test_scores_std.append(tree_scores['test_score'].std())\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Completado: ' + str(round(i / i_max * 100, 2)) + '%')\n",
    "\n",
    "tree_train_scores_mean = np.array(tree_train_scores_mean)\n",
    "tree_train_scores_std = np.array(tree_train_scores_std)\n",
    "tree_test_scores_mean = np.array(tree_test_scores_mean)\n",
    "tree_test_scores_std = np.array(tree_test_scores_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(profundidades, tree_train_scores_mean - tree_train_scores_std,\n",
    "                 tree_train_scores_mean + tree_train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(profundidades, tree_test_scores_mean - tree_test_scores_std,\n",
    "                 tree_test_scores_mean + tree_test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(profundidades, tree_train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(profundidades, tree_test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Test score\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Profundidad Arbol de Decision')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a la gráfica de las sucesivas pruebas, tomaremos como 27 la profundidad ideal del Árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 27, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,\n",
    "    random_state=42, stratify=inmuebles_v1['category_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precisión en el set de entrenamiento: {0: .2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Precisión en el set de testeo: {0: .2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testeo_henry_v1.drop([\"cats_allowed\",\"dogs_allowed\",\"wheelchair_access\", \"electric_vehicle_charge\", \"comes_furnished\"],axis = 1)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv('adelgerbo.csv', index=False, header = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1 --- .72 de accuracy y .68 de recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar bajando a 12 la profundidad del Árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 12, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,\n",
    "    random_state=42, stratify=inmuebles_v1['category_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precisión en el set de entrenamiento: {0: .2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Precisión en el set de testeo: {0: .2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testeo_henry_v1.drop([\"cats_allowed\",\"dogs_allowed\",\"wheelchair_access\", \"electric_vehicle_charge\", \"comes_furnished\"],axis = 1)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv('adelgerbo.csv', index=False, header = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 --- .74 de accuracy y .70 de recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar eliminando las columnas del Estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop([\"state_0\",\"state_1\",\"state_2\",\"state_3\",\"state_4\",\"state_5\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train_scores_mean = []\n",
    "tree_train_scores_std = []\n",
    "tree_test_scores_mean = []\n",
    "tree_test_scores_std = []\n",
    "\n",
    "profundidades = np.arange(1,30,1)\n",
    "i = 0\n",
    "i_max = len(profundidades)\n",
    "for profundidad in profundidades:\n",
    "    i = i + 1\n",
    "    clf = DecisionTreeClassifier(max_depth=profundidad)\n",
    "    tree_scores = cross_validate(clf, X, y, cv=5, return_train_score=True, n_jobs = -1)\n",
    "    \n",
    "    tree_train_scores_mean.append(tree_scores['train_score'].mean())\n",
    "    tree_train_scores_std.append(tree_scores['train_score'].std())\n",
    "    \n",
    "    tree_test_scores_mean.append(tree_scores['test_score'].mean())\n",
    "    tree_test_scores_std.append(tree_scores['test_score'].std())\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Completado: ' + str(round(i / i_max * 100, 2)) + '%')\n",
    "\n",
    "tree_train_scores_mean = np.array(tree_train_scores_mean)\n",
    "tree_train_scores_std = np.array(tree_train_scores_std)\n",
    "tree_test_scores_mean = np.array(tree_test_scores_mean)\n",
    "tree_test_scores_std = np.array(tree_test_scores_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(profundidades, tree_train_scores_mean - tree_train_scores_std,\n",
    "                 tree_train_scores_mean + tree_train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(profundidades, tree_test_scores_mean - tree_test_scores_std,\n",
    "                 tree_test_scores_mean + tree_test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(profundidades, tree_train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(profundidades, tree_test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Test score\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Profundidad Arbol de Decision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 9, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,\n",
    "    random_state=42, stratify=inmuebles_v1['category_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precisión en el set de entrenamiento: {0: .2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Precisión en el set de testeo: {0: .2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testeo_henry_v1.drop([\"cats_allowed\",\"dogs_allowed\",\"wheelchair_access\", \"electric_vehicle_charge\", \"comes_furnished\",\"state_0\",\"state_1\",\"state_2\",\"state_3\",\"state_4\",\"state_5\"],axis = 1)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv('adelgerbo.csv', index=False, header = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 3 --- .79 de accuracy y .78 de recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a revisar nuevamente las correlaciones para evaluar eliminar algunas columnas mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmuebles_v2 = inmuebles_v1.drop([\"cats_allowed\",\"dogs_allowed\",\"wheelchair_access\", \"electric_vehicle_charge\", \"comes_furnished\", \"state_0\",\"state_1\",\"state_2\",\"state_3\",\"state_4\",\"state_5\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the size of the heatmap.\n",
    "plt.figure(figsize=(16, 6))\n",
    "# Store heatmap object in a variable to easily access it when you want to include more features (such as title).\n",
    "# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.\n",
    "heatmap = sns.heatmap(inmuebles_v2.corr(), vmin=-1, vmax=1, annot=True)\n",
    "# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(inmuebles_v2.corr()[['category_price']].sort_values(by='category_price', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Features Correlating with Category_Price', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminaremos \"Smoking Allowed\", \"Publicaciones\", \"Type y \"Beds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop([\"smoking_allowed\",\"publicaciones\",\"type\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train_scores_mean = []\n",
    "tree_train_scores_std = []\n",
    "tree_test_scores_mean = []\n",
    "tree_test_scores_std = []\n",
    "\n",
    "profundidades = np.arange(1,30,1)\n",
    "i = 0\n",
    "i_max = len(profundidades)\n",
    "for profundidad in profundidades:\n",
    "    i = i + 1\n",
    "    clf = DecisionTreeClassifier(max_depth=profundidad)\n",
    "    tree_scores = cross_validate(clf, X, y, cv=5, return_train_score=True, n_jobs = -1)\n",
    "    \n",
    "    tree_train_scores_mean.append(tree_scores['train_score'].mean())\n",
    "    tree_train_scores_std.append(tree_scores['train_score'].std())\n",
    "    \n",
    "    tree_test_scores_mean.append(tree_scores['test_score'].mean())\n",
    "    tree_test_scores_std.append(tree_scores['test_score'].std())\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Completado: ' + str(round(i / i_max * 100, 2)) + '%')\n",
    "\n",
    "tree_train_scores_mean = np.array(tree_train_scores_mean)\n",
    "tree_train_scores_std = np.array(tree_train_scores_std)\n",
    "tree_test_scores_mean = np.array(tree_test_scores_mean)\n",
    "tree_test_scores_std = np.array(tree_test_scores_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(profundidades, tree_train_scores_mean - tree_train_scores_std,\n",
    "                 tree_train_scores_mean + tree_train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(profundidades, tree_test_scores_mean - tree_test_scores_std,\n",
    "                 tree_test_scores_mean + tree_test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(profundidades, tree_train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(profundidades, tree_test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Test score\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Profundidad Arbol de Decision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 11, random_state = 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,\n",
    "    random_state=42) \n",
    "clf.fit(X_train, y_train)\n",
    "print('Precisión en el set de entrenamiento: {0: .2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Precisión en el set de testeo: {0: .2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "testeo_henry_v2 = testeo_henry_v1.drop([\"cats_allowed\",\"dogs_allowed\",\"wheelchair_access\", \"electric_vehicle_charge\", \"comes_furnished\", \"state_0\",\"state_1\",\"state_2\",\"state_3\",\"state_4\",\"state_5\",\"smoking_allowed\",\"publicaciones\",\"type\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testeo_henry_v2\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv('adelgerbo.csv', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos para usar en el metodo no supervisado\n",
    "X.to_csv(\"para_importar_no_supervisado_entrenamiento.csv\", index=False)\n",
    "X_test.to_csv(\"para_importar_no_supervisado_testeo_henry.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a8ac931c2da658386087c1aeacfbaae947468c457a926ada196b02a9b560fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
